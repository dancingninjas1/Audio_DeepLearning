{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using a Pre-trained model for Audio Classification"
      ],
      "metadata": {
        "id": "w7nqjXu5gGeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading all the libraries and the Pre-trained VGGish model from TFHub"
      ],
      "metadata": {
        "id": "NHLTt9cJgO_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import re\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Load the pre-trained VGGish model from TFHub\n",
        "tf_hub_module = hub.load('https://tfhub.dev/google/vggish/1')"
      ],
      "metadata": {
        "id": "UOWVB2T7YQx1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading and unziping the Dataset"
      ],
      "metadata": {
        "id": "IZbLTcyZfo9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/karoldvl/ESC-50/archive/master.zip\n",
        "!unzip master.zip"
      ],
      "metadata": {
        "id": "FP44c7UI7Urv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read the classes"
      ],
      "metadata": {
        "id": "fITqQ_SUfvSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/classes.csv',delimiter = ',') \n",
        "\n",
        "categories = df.columns.tolist()\n",
        "\n",
        "classes =      list(df[categories[0]].values)\n",
        "classes.extend(list(df[categories[1]].values))\n",
        "classes.extend(list(df[categories[2]].values))\n",
        "classes.extend(list(df[categories[3]].values))\n",
        "classes.extend(list(df[categories[4]].values))\n",
        "df"
      ],
      "metadata": {
        "id": "bHTvnGR1YWWu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "7349c73b-0e54-4815-9503-e4e97d619a4a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Animals Natural soundscapes & water sounds  \\\n",
              "0               Dog                               Rain   \n",
              "1           Rooster                          Sea waves   \n",
              "2               Pig                     Crackling fire   \n",
              "3               Cow                           Crickets   \n",
              "4              Frog                     Chirping birds   \n",
              "5               Cat                        Water drops   \n",
              "6               Hen                               Wind   \n",
              "7  Insects (flying)                      Pouring water   \n",
              "8             Sheep                       Toilet flush   \n",
              "9              Crow                       Thunderstorm   \n",
              "\n",
              "  Human/ non-speech sounds Interior/domestic sounds Exterior/urban noises  \n",
              "0              Crying baby               Door knock            Helicopter  \n",
              "1                 Sneezing              Mouse click             Chain saw  \n",
              "2                 Clapping          Keyboard typing                 Siren  \n",
              "3                Breathing         Door,wood creaks              Car horn  \n",
              "4                 Coughing              Can opening                Engine  \n",
              "5                Footsteps          Washing machine                 Train  \n",
              "6                 Laughing           Vacuum cleaner          Church bells  \n",
              "7           Brushing teeth              Clock alarm              Airplane  \n",
              "8                  Snoring               Clock tick              Crackers  \n",
              "9         Drinking/sipping           Glass breaking              Hand saw  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7823afcf-f1bf-4f1f-91b8-f79927ff4c1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Animals</th>\n",
              "      <th>Natural soundscapes &amp; water sounds</th>\n",
              "      <th>Human/ non-speech sounds</th>\n",
              "      <th>Interior/domestic sounds</th>\n",
              "      <th>Exterior/urban noises</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dog</td>\n",
              "      <td>Rain</td>\n",
              "      <td>Crying baby</td>\n",
              "      <td>Door knock</td>\n",
              "      <td>Helicopter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rooster</td>\n",
              "      <td>Sea waves</td>\n",
              "      <td>Sneezing</td>\n",
              "      <td>Mouse click</td>\n",
              "      <td>Chain saw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pig</td>\n",
              "      <td>Crackling fire</td>\n",
              "      <td>Clapping</td>\n",
              "      <td>Keyboard typing</td>\n",
              "      <td>Siren</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cow</td>\n",
              "      <td>Crickets</td>\n",
              "      <td>Breathing</td>\n",
              "      <td>Door,wood creaks</td>\n",
              "      <td>Car horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Frog</td>\n",
              "      <td>Chirping birds</td>\n",
              "      <td>Coughing</td>\n",
              "      <td>Can opening</td>\n",
              "      <td>Engine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Cat</td>\n",
              "      <td>Water drops</td>\n",
              "      <td>Footsteps</td>\n",
              "      <td>Washing machine</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Hen</td>\n",
              "      <td>Wind</td>\n",
              "      <td>Laughing</td>\n",
              "      <td>Vacuum cleaner</td>\n",
              "      <td>Church bells</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Insects (flying)</td>\n",
              "      <td>Pouring water</td>\n",
              "      <td>Brushing teeth</td>\n",
              "      <td>Clock alarm</td>\n",
              "      <td>Airplane</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sheep</td>\n",
              "      <td>Toilet flush</td>\n",
              "      <td>Snoring</td>\n",
              "      <td>Clock tick</td>\n",
              "      <td>Crackers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Crow</td>\n",
              "      <td>Thunderstorm</td>\n",
              "      <td>Drinking/sipping</td>\n",
              "      <td>Glass breaking</td>\n",
              "      <td>Hand saw</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7823afcf-f1bf-4f1f-91b8-f79927ff4c1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7823afcf-f1bf-4f1f-91b8-f79927ff4c1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7823afcf-f1bf-4f1f-91b8-f79927ff4c1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the audio files from the Dataset"
      ],
      "metadata": {
        "id": "4X06PmNMfyA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_files = []\n",
        "PATH = '/content/ESC-50-master/audio/'\n",
        "for file_name in tqdm(os.listdir(PATH)):\n",
        "    try:\n",
        "        audio, sampling_rate = librosa.load(os.path.join(PATH,file_name))\n",
        "        \n",
        "        exp = re.findall('\\d{1,2}.wav',file_name)\n",
        "        \n",
        "        audio_files.append([audio,int(float(exp[0][0:2]))])\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V7RKC0ddbPG",
        "outputId": "81fcd7d9-d565-43d9-b2e6-f78111cddc79"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [00:20<00:00, 95.73it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(audio_files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP_CpPmhcXiw",
        "outputId": "979ec5f2-43f0-46ae-88d2-2745d9d8c5da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_files_load= np.array(audio_files)\n",
        "X = list(audio_files_load[:,0])\n",
        "Y = audio_files_load[:,1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwZb3ADkcSek",
        "outputId": "18d4dc25-f3eb-4b17-cbb3-58cb088f5c6d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-a355b2e66749>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  audio_files_load= np.array(audio_files)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation"
      ],
      "metadata": {
        "id": "P6llzE-zf7QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "size_of_audio_files = len(X[0])\n",
        "number_of_audio_files = len(Y)\n",
        "\n",
        "augmented_audio_files = []\n",
        "\n",
        "for i in range(number_of_audio_files): \n",
        "    \n",
        "    # Adding white noise\n",
        "    X.append(X[i] + 0.005*np.random.randn(size_of_audio_files))\n",
        "    \n",
        "Y = np.r_[Y,Y]\n"
      ],
      "metadata": {
        "id": "CTHtpR1YcOWh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting features of Audiofiles using a pretrained model(VGGish)"
      ],
      "metadata": {
        "id": "CGuet4KXf-XB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "def extract_features(audio_files, labels):\n",
        "\n",
        "\n",
        "    # Extract VGGish features from the audio samples\n",
        "    features = []\n",
        "    valid_labels = []\n",
        "    for i, audio in enumerate(audio_files):\n",
        "        try:\n",
        "\n",
        "            # Extract VGGish features from the audio using the pre-trained model\n",
        "            vggish_features = tf_hub_module(audio)           \n",
        "\n",
        "            # Take the average of the VGGish features for each second of audio\n",
        "            vggish_features_mean = tf.reduce_mean(vggish_features, axis=0)\n",
        "            \n",
        "\n",
        "            # Append the features to the list\n",
        "            features.append(vggish_features_mean.numpy())  \n",
        "\n",
        "            valid_labels.append(labels[i])\n",
        "        except:\n",
        "            print(f\"Failed to load {audio}\")\n",
        "\n",
        "    # Normalize the features\n",
        "    features = numpy.array(features)\n",
        "    features = (features - features.mean()) / features.std()\n",
        "\n",
        "    # Convert the labels to integers\n",
        "    valid_labels = np.array(valid_labels, dtype=np.int32)\n",
        "\n",
        "    return features, valid_labels\n",
        "\n"
      ],
      "metadata": {
        "id": "7lW8FGsQEFPM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features, labels = extract_features(X, Y)\n"
      ],
      "metadata": {
        "id": "p7nJl4JQcufL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting the data and definfing a simple Logistic Regression Classifier"
      ],
      "metadata": {
        "id": "s1LLklzKg0nM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
        "\n",
        "# Train the logistic regression model\n",
        "clf = LogisticRegression(max_iter=500, random_state=7)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f'Test accuracy: {acc*100}')\n",
        "\n"
      ],
      "metadata": {
        "id": "SrWRoN9EDsfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38a207a1-85d9-48bc-8424-6e91867abff3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 84.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the classifier for our case study sample"
      ],
      "metadata": {
        "id": "0KKpbZNfg_QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio, sampling_rate = librosa.load('/content/113203-5-0-0.wav')\n",
        "audio_file= np.array(audio)\n",
        "\n",
        "feature = []\n",
        "vggish_features = tf_hub_module(audio_file)           \n",
        "\n",
        "vggish_features_mean = tf.reduce_mean(vggish_features, axis=0)\n",
        "feature.append(vggish_features_mean.numpy())  \n",
        "\n",
        "label_pred = clf.predict(feature)\n",
        "# Print the predicted label\n",
        "\n",
        "print(f'Predicted label: {classes[label_pred[0]]}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY3_v-_fyzIu",
        "outputId": "9f345ed7-bd91-4cd7-df07-585dda9c575b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: Helicopter\n"
          ]
        }
      ]
    }
  ]
}